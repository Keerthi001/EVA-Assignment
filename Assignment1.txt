#### 1. What are Channels and Kernels (according to EVA)?


Channels:

A channel refer to a filter map in academic perspect. Channels are very important for deep learning networks especially for vision. Channels are very important for vision prospective. 

Image is divided into 3 channels (red, green and blue). Actually the image is combination of three colors red, green and green. Single channel represents or called as grey scale image (black and white color)

Images are printed in newspaper in four colors (CMYK)

For example if we turn off the two channels like red and blue then computer can identifies remaining color or leftout color channel like green where as photo shop will identifies one channel then it will show in black and white color. Color means multiple channels. if we do not have multiple channels then it become black and white channel.

Kernels:

In Convolutional neural network, the kernel is nothing but a filter that is used to extract the features from the images. So, kernel is also called as feature extractor. The kernel is a matrix that moves over the input data, performs the dot product with the sub-region of input data, and gets the output as the matrix of dot products.

Kernel is also called as 3 x 3 Matrix.

Kernel performs convolution with the image then it generates channel.



#### 2. Why should we (nearly) always use 3x3 kernels?


3 X 3 size kernels are used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between a kernel and an image. While applying 2D convolutions like 3X3 convolutions on images, a 3X3 convolution filter, in general will always have a third dimension in size.

We would usually have a 3x3 kernel size with 256 input and output channels. Instead of this, we first do a 1x1 convolutional layer bringing the number of channels down to something like 32. Then we perform the convolution with a 3x3 kernel size. ... It reduces the size of the input vector, the number of channels.

Using 3x3 we can create a filter of any size my addling mulitple layers, for ex. by using 2 layers of 3x3 we get 5x5 and so on.



#### 3. How many times to we need to perform 3x3 convolutions operations to reach close to 1x1 from 199x199 (type each layer output like 199x199 > 197x197...)


199x199 > 3x3 > 197x197
197x197 > 3x3 > 195x195
195x195 > 3x3 > 193x193
193x193 > 3x3 > 191x191
191x191 > 3x3 > 189x189
189x189 > 3x3 > 187x187
187x187 > 3x3 > 185x185
185x185 > 3x3 > 183x183	
183x183 > 3x3 > 181x181
181x181 > 3x3 > 179x179
179x179 > 3x3 > 177x177
177x177 > 3x3 > 175x175
175x175 > 3x3 > 173x173
173x173 > 3x3 > 171x171
171x171 > 3x3 > 169x169
169x169 > 3x3 > 167x167
167x167 > 3x3 > 165x165
165x165 > 3x3 > 163x163
163x163 > 3x3 > 161x161
161x161 > 3x3 > 159x159
159x159 > 3x3 > 157x157
157x157 > 3x3 > 155x155
155x155 > 3x3 > 153x153
153x153 > 3x3 > 151x151
151x151 > 3x3 > 149x149
149x149 > 3x3 > 147x147
147x147 > 3x3 > 145x145
145x145 > 3x3 > 143x143
143x143 > 3x3 > 141x141
141x141 > 3x3 > 139x139
139x139 > 3x3 > 137x137
137x137 > 3x3 > 135x135
135x135 > 3x3 > 133x133
133x133 > 3x3 > 131x131
131x131 > 3x3 > 129x129
129x129 > 3x3 > 127x127
127x127 > 3x3 > 125x125
125x125 > 3x3 > 123x123
123x123 > 3x3 > 121x121
121x121 > 3x3 > 119x119
119x119 > 3x3 > 117x117
117x117 > 3x3 > 115x115
115x115 > 3x3 > 113x113
113x113 > 3x3 > 111x111
111x111 > 3x3 > 109x109
109x109 > 3x3 > 107x107
107x107 > 3x3 > 105x105
105x105 > 3x3 > 103x103
103x103 > 3x3 > 101x101
101x101 > 3x3 > 99x99
99x99 > 3x3 > 97x97
97x97 > 3x3 > 95x95
95x95 > 3x3 > 93x93
93x93 > 3x3 > 91x91
91x91 > 3x3 > 89x89
89x89 > 3x3 > 87x87
87x87 > 3x3 > 85x85
85x85 > 3x3 > 83x83
83x83 > 3x3 > 81x81
81x81 > 3x3 > 79x79
79x79 > 3x3 > 77x77
77x77 > 3x3 > 75x75
75x75 > 3x3 > 73x73
73x73 > 3x3 > 71x71
71x71 > 3x3 > 69x69
69x69 > 3x3 > 67x67
67x67 > 3x3 > 65x65
65x65 > 3x3 > 63x63 
63x63 > 3x3 > 61x61
61x61 > 3x3 > 59x59
59x59 > 3x3 > 57x57
57x57 > 3x3 > 55x55
55x55 > 3x3 > 53x53
53x53 > 3x3 > 51x51
51x51 > 3x3 > 49x49
49x49 > 3x3 > 47x47
47x47 > 3x3 > 45x45
45x45 > 3x3 > 43x43
43x43 > 3x3 > 41x41
41x41 > 3x3 > 39x39
39x39 > 3x3 > 37x37
37x37 > 3x3 > 35x35
35x35 > 3x3 > 33x33
33x33 > 3x3 > 31x31
31x31 > 3x3 > 29x29
29x29 > 3x3 > 27x27
27x27 > 3x3 > 25x25
25x25 > 3x3 > 23x23
23x23 > 3x3 > 21x21
21x21 > 3x3 > 19x19
19x19 > 3x3 > 17x17
17x17 > 3x3 > 15x15
15x15 > 3x3 > 13x13
13x13 > 3x3 > 11x11
11x11 > 3x3 > 9x9
9x9 > 3x3 > 7x7
7x7 > 3x3 > 5x5
5x5 > 3x3 > 3x3
3x3 > 3x3 > 1x1  


####  4. How are kernels initialized? 


kernels are initialized randomly. 

Initializing conv layer kernel is an active field of research. There are various ways to initialize, and it all depends on the network architecture. In each layer, the calculated gradient is scaled by the learning rate, and is added to the weights, or the kernel if the layer is convolution layer.

The kernels are usually initialized at a seemingly arbitrary value and then use a gradient descent optimizer to optimize the values so that the kernels solve the problem.

Set all values to 1 or 0 or another constant.



#### 5. What happens during the training of a DNN?


A DNN is a collection of neurons organized in a sequence of multiple layers, where neurons receive as input the neuron activations from the previous layer, and perform a simple computation (e.g. a weighted sum of the input followed by a nonlinear activation).


Deep learning algorithms utilizes supervised and unsupervised learning algorithms to train the outputs through the delivered inputs. The circles are represented as neurons that are interconnected. The neurons are classified into three different hierarchy of layers termed as Input, Hidden and Output Layers. The first neuron layer i.e. input layer receives the input data and passes it to the first hidden layer. The hidden layers perform the computations on the received data. The biggest challenge under neural networks creation is to decide the number of neurons and a number of hidden layers. Finally, the output layer produces the required output.

Every connection between the neurons consists of weights, it denotes the significance of the input values. In order to standardize the outputs, an activation function is used. For training the network, two important measures are considered. The first is to create a large data set and the second is large computational power. The ‘Deep’ in deep learning signifies the number of hidden layers the model is using to train the data set. 


	